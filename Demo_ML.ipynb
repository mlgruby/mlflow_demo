{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using bucket sagemaker-eu-west-1-505529183986\n"
     ]
    }
   ],
   "source": [
    "import datetime\n",
    "import tarfile\n",
    "\n",
    "import mlflow\n",
    "\n",
    "import boto3\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sagemaker import get_execution_role\n",
    "from mlflow.sagemaker import deploy \n",
    "import sagemaker\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.datasets import load_boston\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "from sqlalchemy import create_engine\n",
    "\n",
    "sm_boto3 = boto3.client('sagemaker')\n",
    "\n",
    "sess = sagemaker.Session()\n",
    "\n",
    "region = sess.boto_session.region_name\n",
    "\n",
    "bucket = sess.default_bucket()  # this could also be a hard-coded bucket name\n",
    "\n",
    "print('Using bucket ' + bucket)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "load data from redshift and then prepare test and train datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "engine = create_engine('postgresql://mlflow_admin:EdBx6FUjDEgvG5@mlflow-redshift0.cdwamzbulp7n.eu-west-1.redshift.amazonaws.com:5439/dev')\n",
    "data_frame = pd.read_sql_query('SELECT * FROM boston_data;', engine)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainX, testX = train_test_split(data_frame, test_size=0.25, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainX.to_csv('boston_train.csv')\n",
    "testX.to_csv('boston_test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [],
   "source": [
    "# send data to S3. SageMaker will take training data from s3\n",
    "trainpath = sess.upload_data(\n",
    "    path='boston_train.csv', bucket=bucket,\n",
    "    key_prefix='sagemaker/sklearncontainer')\n",
    "\n",
    "testpath = sess.upload_data(\n",
    "    path='boston_test.csv', bucket=bucket,\n",
    "    key_prefix='sagemaker/sklearncontainer')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Writing a Script Mode script"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting script.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile script.py\n",
    "\n",
    "import argparse\n",
    "import os\n",
    "\n",
    "import mlflow\n",
    "from mlflow.sklearn import log_model\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.externals import joblib\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "if __name__ =='__main__':\n",
    "\n",
    "    print('extracting arguments')\n",
    "    parser = argparse.ArgumentParser()\n",
    "\n",
    "    # hyperparameters sent by the client are passed as command-line arguments to the script.\n",
    "    # to simplify the demo we don't use all sklearn RandomForest hyperparameters\n",
    "    parser.add_argument('--n-estimators', type=int, default=10)\n",
    "    parser.add_argument('--min-samples-leaf', type=int, default=3)\n",
    "\n",
    "    # Data, model, and output directories\n",
    "    parser.add_argument('--model-dir', type=str, default=os.environ.get('SM_MODEL_DIR'))\n",
    "    parser.add_argument('--train', type=str, default=os.environ.get('SM_CHANNEL_TRAIN'))\n",
    "    parser.add_argument('--test', type=str, default=os.environ.get('SM_CHANNEL_TEST'))\n",
    "    parser.add_argument('--train-file', type=str, default='boston_train.csv')\n",
    "    parser.add_argument('--test-file', type=str, default='boston_test.csv')\n",
    "#     parser.add_argument('--data_table', type=str, default='boston_data')\n",
    "    parser.add_argument('--features', type=str)  # in this script we ask user to explicitly name features\n",
    "    parser.add_argument('--target', type=str) # in this script we ask user to explicitly name the target\n",
    "\n",
    "    args, _ = parser.parse_known_args()\n",
    "\n",
    "    print('reading data')\n",
    "    train_df = pd.read_csv(os.path.join(args.train, args.train_file))\n",
    "    test_df = pd.read_csv(os.path.join(args.test, args.test_file))\n",
    "#     engine = create_engine('postgresql://mlflow_admin:EdBx6FUjDEgvG5@mlflow-redshift0.cdwamzbulp7n.eu-west-1.redshift.amazonaws.com:5439/dev')\n",
    "#     data_frame = pd.read_sql_query('SELECT * FROM boston_data;', engine)\n",
    "#     train_df, test_df = train_test_split(data_frame, test_size=0.25, random_state=42)\n",
    "\n",
    "    print('building training and testing datasets')\n",
    "    X_train = train_df[args.features.split()]\n",
    "    X_test = test_df[args.features.split()]\n",
    "    y_train = train_df[args.target]\n",
    "    y_test = test_df[args.target]\n",
    "\n",
    "    # setting MLFlow tracker \n",
    "    uri = \"http://internal-a19641f33008a11eaa1590a387f0e3c9-331214759.eu-west-1.elb.amazonaws.com:5000\"\n",
    "    mlflow.set_tracking_uri(uri)\n",
    "    mlflow.set_experiment(\"ml-demo\")\n",
    "    \n",
    "    # train\n",
    "    print('training model')\n",
    "    with mlflow.start_run():\n",
    "        model = RandomForestRegressor(\n",
    "            n_estimators=args.n_estimators,\n",
    "            min_samples_leaf=args.min_samples_leaf,\n",
    "            n_jobs=-1)\n",
    "\n",
    "        model.fit(X_train, y_train)\n",
    "\n",
    "        # print abs error, rmse and r2_score\n",
    "        print('validating model')\n",
    "        y_test_predict = model.predict(X_test)\n",
    "        abs_err = np.abs(y_test_predict - y_test)\n",
    "#         rmse = (np.sqrt(mean_squared_error(y_test_predict, y_test)))\n",
    "#         r2 = r2_score(y_test, y_test_predict)\n",
    "#         print('rmse: {}, r2_score: {}'.format(rmse, r2))\n",
    "#         mlflow.log_metric('rmse', rmse)\n",
    "#         mlflow.log_metric('r2', r2)\n",
    "\n",
    "\n",
    "        # print couple perf metrics\n",
    "        for q in [10, 50, 90]:\n",
    "            print('AE-at-' + str(q) + 'th-percentile: '\n",
    "                  + str(np.percentile(a=abs_err, q=q)))\n",
    "            mlflow.log_metric('AE-at-' + str(q) + 'th-percentile', np.percentile(a=abs_err, q=q))\n",
    "\n",
    "        print(args.min_samples_leaf)\n",
    "        \n",
    "        mlflow.log_param(\"n_estimators\", args.n_estimators)\n",
    "        mlflow.log_param(\"min_samples_leaf\", args.min_samples_leaf)\n",
    "        log_model(model, \"model\")\n",
    "        mlflow.log_artifcat()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages/cloudpickle/cloudpickle.py:47: DeprecationWarning: the imp module is deprecated in favour of importlib; see the module's documentation for alternative uses\n",
      "  import imp\n",
      "extracting arguments\n",
      "reading data\n",
      "building training and testing datasets\n",
      "training model\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages/IPython/lib/pretty.py:91: DeprecationWarning: IPython.utils.signatures backport for Python 2 is deprecated in IPython 6, which only supports Python 3\n",
      "  from IPython.utils.signatures import signature\n",
      "validating model\n",
      "AE-at-10th-percentile: 0.3721773623439724\n",
      "AE-at-50th-percentile: 1.7404672064140279\n",
      "AE-at-90th-percentile: 5.067331733496558\n",
      "5\n"
     ]
    }
   ],
   "source": [
    "! python script.py --n-estimators 600 \\\n",
    "                   --min-samples-leaf 5 \\\n",
    "                   --train /home/ec2-user/SageMaker/mlflow_demo \\\n",
    "                   --test /home/ec2-user/SageMaker/mlflow_demo \\\n",
    "                   --features 'crim zn indus chas nox rm age dis rad tax ptratio b lstat' \\\n",
    "                   --target target"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SageMaker Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Launching a training job with the Python SDK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.sklearn.estimator import SKLearn\n",
    "\n",
    "sklearn_estimator = SKLearn(\n",
    "    entry_point='script.py',\n",
    "    role = get_execution_role(),\n",
    "    train_instance_count=1,\n",
    "    train_instance_type='ml.c5.xlarge',\n",
    "    framework_version='0.20.0',\n",
    "    metric_definitions=[\n",
    "        {'Name': 'median-AE',\n",
    "         'Regex': \"AE-at-50th-percentile: ([0-9.]+).*$\"}],\n",
    "    hyperparameters = {'n-estimators': 100,\n",
    "                       'min-samples-leaf': 3,\n",
    "                       'features': 'crim zn indus chas nox rm age dis rad tax ptratio b lstat',\n",
    "                       'target': 'target'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [],
   "source": [
    "# launch training job, with asynchronous call\n",
    "sklearn_estimator.fit({'train':trainpath, 'test': testpath}, wait=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deploy the model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019/11/08 11:41:48 INFO mlflow.sagemaker: Using the python_function flavor for deployment!\n",
      "2019/11/08 11:41:49 INFO mlflow.sagemaker: tag response: {'ResponseMetadata': {'RequestId': '65331DBD49E8D987', 'HostId': 'wnqnDmR8oVzR3Ce4Nf9RpEOQQB08P212bQUc09gSd98L619kfK5V8f6v2x3p3WTAfmfpBGjSlzY=', 'HTTPStatusCode': 200, 'HTTPHeaders': {'x-amz-id-2': 'wnqnDmR8oVzR3Ce4Nf9RpEOQQB08P212bQUc09gSd98L619kfK5V8f6v2x3p3WTAfmfpBGjSlzY=', 'x-amz-request-id': '65331DBD49E8D987', 'date': 'Fri, 08 Nov 2019 11:41:50 GMT', 'content-length': '0', 'server': 'AmazonS3'}, 'RetryAttempts': 0}}\n",
      "2019/11/08 11:41:49 INFO mlflow.sagemaker: Found active endpoint with arn: arn:aws:sagemaker:eu-west-1:505529183986:endpoint/ml-demo. Updating...\n",
      "2019/11/08 11:41:49 INFO mlflow.sagemaker: Created new model with arn: arn:aws:sagemaker:eu-west-1:505529183986:model/ml-demo-model-7xegvplrt-cuyrosaftobg\n",
      "2019/11/08 11:41:49 INFO mlflow.sagemaker: Created new endpoint configuration with arn: arn:aws:sagemaker:eu-west-1:505529183986:endpoint-config/ml-demo-config-fgnux9dvtsopjfwowy7hya\n",
      "2019/11/08 11:41:49 INFO mlflow.sagemaker: Updated endpoint with new configuration!\n",
      "2019/11/08 11:41:49 INFO mlflow.sagemaker: Waiting for the deployment operation to complete...\n",
      "2019/11/08 11:41:49 INFO mlflow.sagemaker: The operation is still in progress.\n",
      "2019/11/08 11:42:10 INFO mlflow.sagemaker: The update operation is still in progress. Current endpoint status: \"Updating\"\n",
      "2019/11/08 11:42:30 INFO mlflow.sagemaker: The update operation is still in progress. Current endpoint status: \"Updating\"\n",
      "2019/11/08 11:42:50 INFO mlflow.sagemaker: The update operation is still in progress. Current endpoint status: \"Updating\"\n",
      "2019/11/08 11:43:10 INFO mlflow.sagemaker: The update operation is still in progress. Current endpoint status: \"Updating\"\n",
      "2019/11/08 11:43:31 INFO mlflow.sagemaker: The update operation is still in progress. Current endpoint status: \"Updating\"\n",
      "2019/11/08 11:43:51 INFO mlflow.sagemaker: The update operation is still in progress. Current endpoint status: \"Updating\"\n",
      "2019/11/08 11:44:11 INFO mlflow.sagemaker: The update operation is still in progress. Current endpoint status: \"Updating\"\n",
      "2019/11/08 11:44:31 INFO mlflow.sagemaker: The update operation is still in progress. Current endpoint status: \"Updating\"\n",
      "2019/11/08 11:44:52 INFO mlflow.sagemaker: The update operation is still in progress. Current endpoint status: \"Updating\"\n",
      "2019/11/08 11:45:12 INFO mlflow.sagemaker: The update operation is still in progress. Current endpoint status: \"Updating\"\n",
      "2019/11/08 11:45:32 INFO mlflow.sagemaker: The update operation is still in progress. Current endpoint status: \"Updating\"\n",
      "2019/11/08 11:45:52 INFO mlflow.sagemaker: The update operation is still in progress. Current endpoint status: \"Updating\"\n",
      "2019/11/08 11:46:13 INFO mlflow.sagemaker: The update operation is still in progress. Current endpoint status: \"Updating\"\n",
      "2019/11/08 11:46:33 INFO mlflow.sagemaker: The update operation is still in progress. Current endpoint status: \"Updating\"\n",
      "2019/11/08 11:46:53 INFO mlflow.sagemaker: The update operation is still in progress. Current endpoint status: \"Updating\"\n",
      "2019/11/08 11:47:14 INFO mlflow.sagemaker: The update operation is still in progress. Current endpoint status: \"Updating\"\n",
      "2019/11/08 11:47:34 INFO mlflow.sagemaker: The update operation is still in progress. Current endpoint status: \"Updating\"\n",
      "2019/11/08 11:47:54 INFO mlflow.sagemaker: The update operation is still in progress. Current endpoint status: \"Updating\"\n",
      "2019/11/08 11:48:14 INFO mlflow.sagemaker: The update operation is still in progress. Current endpoint status: \"Updating\"\n",
      "2019/11/08 11:48:35 INFO mlflow.sagemaker: The update operation is still in progress. Current endpoint status: \"Updating\"\n",
      "2019/11/08 11:48:55 INFO mlflow.sagemaker: The update operation is still in progress. Current endpoint status: \"Updating\"\n",
      "2019/11/08 11:49:00 INFO mlflow.sagemaker: The deployment operation completed successfully with message: \"The SageMaker endpoint was updated successfully.\"\n",
      "2019/11/08 11:49:00 INFO mlflow.sagemaker: Cleaning up unused resources...\n",
      "2019/11/08 11:49:00 INFO mlflow.sagemaker: Deleted model with arn: arn:aws:sagemaker:eu-west-1:505529183986:model/ml-demo-model-kt73bgjhrnowicewspyrww\n",
      "2019/11/08 11:49:00 INFO mlflow.sagemaker: Deleted endpoint configuration with arn: arn:aws:sagemaker:eu-west-1:505529183986:endpoint-config/ml-demo-config-kfalg3vtsjiab17vjv2bdmg\n"
     ]
    }
   ],
   "source": [
    "ml_endpoint_name = 'ml-demo'\n",
    "deploy(app_name=ml_endpoint_name, model_uri='s3://3stripes-mlflow-artifacts/1/dc33eb2ba2a44e6b8301f5e97b3c5af5/artifacts/model/',\n",
    "                       execution_role_arn=get_execution_role(), bucket='3stripes-mlflow-artifacts', \n",
    "                       image_url='505529183986.dkr.ecr.eu-west-1.amazonaws.com/mlflow-pyfunc:1.4.0', \n",
    "                       region_name='eu-west-1', mode=mlflow.sagemaker.DEPLOYMENT_MODE_REPLACE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Inference "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "runtime = boto3.client('sagemaker-runtime')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[33.85619167709908]\n"
     ]
    }
   ],
   "source": [
    "# csv serialization\n",
    "response = runtime.invoke_endpoint(\n",
    "    EndpointName=endpoint_name,\n",
    "    Body=testX[testX.columns[:-1]].iloc[:2].to_csv(header=False, index=False).encode('utf-8'),\n",
    "    ContentType='text/csv')\n",
    "\n",
    "print(response['Body'].read().decode(\"utf-8\") )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>crim</th>\n",
       "      <th>zn</th>\n",
       "      <th>indus</th>\n",
       "      <th>chas</th>\n",
       "      <th>nox</th>\n",
       "      <th>rm</th>\n",
       "      <th>age</th>\n",
       "      <th>dis</th>\n",
       "      <th>rad</th>\n",
       "      <th>tax</th>\n",
       "      <th>ptratio</th>\n",
       "      <th>b</th>\n",
       "      <th>lstat</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>173</th>\n",
       "      <td>0.0315</td>\n",
       "      <td>95.0</td>\n",
       "      <td>1.47</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.403</td>\n",
       "      <td>6.975</td>\n",
       "      <td>15.3</td>\n",
       "      <td>7.6534</td>\n",
       "      <td>3.0</td>\n",
       "      <td>402.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>396.9</td>\n",
       "      <td>4.56</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       crim    zn  indus  chas    nox     rm   age     dis  rad    tax  \\\n",
       "173  0.0315  95.0   1.47   0.0  0.403  6.975  15.3  7.6534  3.0  402.0   \n",
       "\n",
       "     ptratio      b  lstat  \n",
       "173     17.0  396.9   4.56  "
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testX[testX.columns[:-1]].iloc[:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "uri = \"http://internal-a19641f33008a11eaa1590a387f0e3c9-331214759.eu-west-1.elb.amazonaws.com:5000\"\n",
    "mlflow_client = mlflow.tracking.MlflowClient(uri)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'info': {'artifact_uri': 's3://3stripes-mlflow-artifacts/1/f19af831e29748e69afe1ecd02404bb7/artifacts',\n",
       "  'end_time': 1573212611607,\n",
       "  'experiment_id': '1',\n",
       "  'lifecycle_stage': 'active',\n",
       "  'run_id': 'f19af831e29748e69afe1ecd02404bb7',\n",
       "  'run_uuid': 'f19af831e29748e69afe1ecd02404bb7',\n",
       "  'start_time': 1573212609959,\n",
       "  'status': 'FINISHED',\n",
       "  'user_id': 'ec2-user'},\n",
       " 'data': {'metrics': {'AE-at-10th-percentile': 0.363594086901652,\n",
       "   'AE-at-50th-percentile': 1.50249762300608,\n",
       "   'AE-at-90th-percentile': 4.93729709268675},\n",
       "  'params': {'n_estimators': '400', 'min_samples_leaf': '4'},\n",
       "  'tags': {'mlflow.source.name': 'script.py',\n",
       "   'mlflow.source.git.commit': '4ea8cd6b1d7acdeab6e86ae727be6dde70d1c4f5',\n",
       "   'mlflow.source.type': 'LOCAL',\n",
       "   'mlflow.user': 'ec2-user'}}}"
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mlflow_client.get_run('f19af831e29748e69afe1ecd02404bb7').to_dictionary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
