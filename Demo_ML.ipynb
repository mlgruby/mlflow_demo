{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using bucket sagemaker-eu-west-1-505529183986\n"
     ]
    }
   ],
   "source": [
    "import datetime\n",
    "import tarfile\n",
    "\n",
    "import mlflow\n",
    "\n",
    "import boto3\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sagemaker import get_execution_role\n",
    "from mlflow.sagemaker import deploy \n",
    "import sagemaker\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.datasets import load_boston\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "from sqlalchemy import create_engine\n",
    "\n",
    "sm_boto3 = boto3.client('sagemaker')\n",
    "\n",
    "sess = sagemaker.Session()\n",
    "\n",
    "region = sess.boto_session.region_name\n",
    "\n",
    "bucket = sess.default_bucket()  # this could also be a hard-coded bucket name\n",
    "\n",
    "print('Using bucket ' + bucket)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "load data from redshift and then prepare test and train datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages/psycopg2/__init__.py:144: UserWarning: The psycopg2 wheel package will be renamed from release 2.8; in order to keep installing from binary please use \"pip install psycopg2-binary\" instead. For details see: <http://initd.org/psycopg/docs/install.html#binary-install-from-pypi>.\n",
      "  \"\"\")\n"
     ]
    }
   ],
   "source": [
    "engine = create_engine('postgresql://mlflow_admin:EdBx6FUjDEgvG5@mlflow-redshift0.cdwamzbulp7n.eu-west-1.redshift.amazonaws.com:5439/dev')\n",
    "data_frame = pd.read_sql_query('SELECT * FROM boston_data;', engine)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainX, testX = train_test_split(data_frame, test_size=0.25, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainX.to_csv('boston_train.csv')\n",
    "testX.to_csv('boston_test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# send data to S3. SageMaker will take training data from s3\n",
    "trainpath = sess.upload_data(\n",
    "    path='boston_train.csv', bucket=bucket,\n",
    "    key_prefix='sagemaker/sklearncontainer')\n",
    "\n",
    "testpath = sess.upload_data(\n",
    "    path='boston_test.csv', bucket=bucket,\n",
    "    key_prefix='sagemaker/sklearncontainer')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Writing a Script Mode script"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting script.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile script.py\n",
    "\n",
    "import argparse\n",
    "import os\n",
    "\n",
    "import mlflow\n",
    "from mlflow.sklearn import log_model\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.externals import joblib\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "if __name__ =='__main__':\n",
    "\n",
    "    print('extracting arguments')\n",
    "    parser = argparse.ArgumentParser()\n",
    "\n",
    "    # hyperparameters sent by the client are passed as command-line arguments to the script.\n",
    "    # to simplify the demo we don't use all sklearn RandomForest hyperparameters\n",
    "    parser.add_argument('--n-estimators', type=int, default=10)\n",
    "    parser.add_argument('--min-samples-leaf', type=int, default=3)\n",
    "\n",
    "    # Data, model, and output directories\n",
    "    parser.add_argument('--model-dir', type=str, default=os.environ.get('SM_MODEL_DIR'))\n",
    "    parser.add_argument('--train', type=str, default=os.environ.get('SM_CHANNEL_TRAIN'))\n",
    "    parser.add_argument('--test', type=str, default=os.environ.get('SM_CHANNEL_TEST'))\n",
    "    parser.add_argument('--train-file', type=str, default='boston_train.csv')\n",
    "    parser.add_argument('--test-file', type=str, default='boston_test.csv')\n",
    "#     parser.add_argument('--data_table', type=str, default='boston_data')\n",
    "    parser.add_argument('--features', type=str)  # in this script we ask user to explicitly name features\n",
    "    parser.add_argument('--target', type=str) # in this script we ask user to explicitly name the target\n",
    "\n",
    "    args, _ = parser.parse_known_args()\n",
    "\n",
    "    print('reading data')\n",
    "    train_df = pd.read_csv(os.path.join(args.train, args.train_file))\n",
    "    test_df = pd.read_csv(os.path.join(args.test, args.test_file))\n",
    "#     engine = create_engine('postgresql://mlflow_admin:EdBx6FUjDEgvG5@mlflow-redshift0.cdwamzbulp7n.eu-west-1.redshift.amazonaws.com:5439/dev')\n",
    "#     data_frame = pd.read_sql_query('SELECT * FROM boston_data;', engine)\n",
    "#     train_df, test_df = train_test_split(data_frame, test_size=0.25, random_state=42)\n",
    "\n",
    "    print('building training and testing datasets')\n",
    "    X_train = train_df[args.features.split()]\n",
    "    X_test = test_df[args.features.split()]\n",
    "    y_train = train_df[args.target]\n",
    "    y_test = test_df[args.target]\n",
    "\n",
    "    # setting MLFlow tracker \n",
    "    uri = \"http://internal-a19641f33008a11eaa1590a387f0e3c9-331214759.eu-west-1.elb.amazonaws.com:5000\"\n",
    "    mlflow.set_tracking_uri(uri)\n",
    "    mlflow.set_experiment(\"ml-demo\")\n",
    "    \n",
    "    # train\n",
    "    print('training model')\n",
    "    with mlflow.start_run():\n",
    "        model = RandomForestRegressor(\n",
    "            n_estimators=args.n_estimators,\n",
    "            min_samples_leaf=args.min_samples_leaf,\n",
    "            n_jobs=-1)\n",
    "\n",
    "        model.fit(X_train, y_train)\n",
    "\n",
    "        # print abs error, rmse and r2_score\n",
    "        print('validating model')\n",
    "        y_test_predict = model.predict(X_test)\n",
    "        abs_err = np.abs(y_test_predict - y_test)\n",
    "#         rmse = (np.sqrt(mean_squared_error(y_test_predict, y_test)))\n",
    "#         r2 = r2_score(y_test, y_test_predict)\n",
    "#         print('rmse: {}, r2_score: {}'.format(rmse, r2))\n",
    "#         mlflow.log_metric('rmse', rmse)\n",
    "#         mlflow.log_metric('r2', r2)\n",
    "\n",
    "\n",
    "        # print couple perf metrics\n",
    "        for q in [10, 50, 90]:\n",
    "            print('AE-at-' + str(q) + 'th-percentile: '\n",
    "                  + str(np.percentile(a=abs_err, q=q)))\n",
    "            mlflow.log_metric('AE-at-' + str(q) + 'th-percentile', np.percentile(a=abs_err, q=q))\n",
    "\n",
    "        print(args.min_samples_leaf)\n",
    "        \n",
    "        mlflow.log_param(\"n_estimators\", args.n_estimators)\n",
    "        mlflow.log_param(\"min_samples_leaf\", args.min_samples_leaf)\n",
    "        log_model(model, \"model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages/cloudpickle/cloudpickle.py:47: DeprecationWarning: the imp module is deprecated in favour of importlib; see the module's documentation for alternative uses\n",
      "  import imp\n",
      "extracting arguments\n",
      "reading data\n",
      "building training and testing datasets\n",
      "training model\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages/IPython/lib/pretty.py:91: DeprecationWarning: IPython.utils.signatures backport for Python 2 is deprecated in IPython 6, which only supports Python 3\n",
      "  from IPython.utils.signatures import signature\n",
      "validating model\n",
      "rmse: 4.545474177877792, r2_score: 0.7451258823701463\n",
      "10\n"
     ]
    }
   ],
   "source": [
    "! python script.py --n-estimators 600 \\\n",
    "                   --min-samples-leaf 10 \\\n",
    "                   --train /home/ec2-user/SageMaker/mlflow_demo \\\n",
    "                   --test /home/ec2-user/SageMaker/mlflow_demo \\\n",
    "                   --features 'crim zn indus chas nox rm age dis rad tax ptratio b lstat' \\\n",
    "                   --target target"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SageMaker Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Launching a training job with the Python SDK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.sklearn.estimator import SKLearn\n",
    "\n",
    "sklearn_estimator = SKLearn(\n",
    "    entry_point='script.py',\n",
    "    role = get_execution_role(),\n",
    "    train_instance_count=1,\n",
    "    train_instance_type='ml.c5.xlarge',\n",
    "    framework_version='0.20.0',\n",
    "    metric_definitions=[\n",
    "        {'Name': 'median-AE',\n",
    "         'Regex': \"AE-at-50th-percentile: ([0-9.]+).*$\"}],\n",
    "    hyperparameters = {'n-estimators': 100,\n",
    "                       'min-samples-leaf': 3,\n",
    "                       'features': 'crim zn indus chas nox rm age dis rad tax ptratio b lstat',\n",
    "                       'target': 'target'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [],
   "source": [
    "# launch training job, with asynchronous call\n",
    "sklearn_estimator.fit({'train':trainpath, 'test': testpath}, wait=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deploy the model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "ml_endpoint_name = 'ml-demo'\n",
    "deploy(app_name=ml_endpoint_name, model_uri='s3://3stripes-mlflow-artifacts/1/dc33eb2ba2a44e6b8301f5e97b3c5af5/artifacts/model/',\n",
    "                       execution_role_arn=get_execution_role(), bucket='3stripes-mlflow-artifacts', \n",
    "                       image_url='505529183986.dkr.ecr.eu-west-1.amazonaws.com/mlflow-pyfunc:1.4.0', \n",
    "                       region_name='eu-west-1')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Inference "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "runtime = boto3.client('sagemaker-runtime')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[33.85619167709908]\n"
     ]
    }
   ],
   "source": [
    "# csv serialization\n",
    "response = runtime.invoke_endpoint(\n",
    "    EndpointName=endpoint_name,\n",
    "    Body=testX[testX.columns[:-1]].iloc[:2].to_csv(header=False, index=False).encode('utf-8'),\n",
    "    ContentType='text/csv')\n",
    "\n",
    "print(response['Body'].read().decode(\"utf-8\") )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>crim</th>\n",
       "      <th>zn</th>\n",
       "      <th>indus</th>\n",
       "      <th>chas</th>\n",
       "      <th>nox</th>\n",
       "      <th>rm</th>\n",
       "      <th>age</th>\n",
       "      <th>dis</th>\n",
       "      <th>rad</th>\n",
       "      <th>tax</th>\n",
       "      <th>ptratio</th>\n",
       "      <th>b</th>\n",
       "      <th>lstat</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>173</th>\n",
       "      <td>0.0315</td>\n",
       "      <td>95.0</td>\n",
       "      <td>1.47</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.403</td>\n",
       "      <td>6.975</td>\n",
       "      <td>15.3</td>\n",
       "      <td>7.6534</td>\n",
       "      <td>3.0</td>\n",
       "      <td>402.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>396.9</td>\n",
       "      <td>4.56</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       crim    zn  indus  chas    nox     rm   age     dis  rad    tax  \\\n",
       "173  0.0315  95.0   1.47   0.0  0.403  6.975  15.3  7.6534  3.0  402.0   \n",
       "\n",
       "     ptratio      b  lstat  \n",
       "173     17.0  396.9   4.56  "
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testX[testX.columns[:-1]].iloc[:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
